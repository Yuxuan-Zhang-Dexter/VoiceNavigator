Metadata-Version: 2.1
Name: self-operating-computer
Version: 1.5.7
Description-Content-Type: text/markdown
License-File: LICENSE
Requires-Dist: annotated-types==0.6.0
Requires-Dist: anyio==3.7.1
Requires-Dist: certifi==2023.7.22
Requires-Dist: charset-normalizer==3.3.2
Requires-Dist: colorama==0.4.6
Requires-Dist: contourpy==1.2.0
Requires-Dist: cycler==0.12.1
Requires-Dist: distro==1.8.0
Requires-Dist: EasyProcess==1.1
Requires-Dist: entrypoint2==1.1
Requires-Dist: exceptiongroup==1.1.3
Requires-Dist: fonttools==4.44.0
Requires-Dist: h11==0.14.0
Requires-Dist: httpcore==1.0.2
Requires-Dist: httpx>=0.25.2
Requires-Dist: idna==3.4
Requires-Dist: importlib-resources==6.1.1
Requires-Dist: kiwisolver==1.4.5
Requires-Dist: matplotlib==3.8.1
Requires-Dist: MouseInfo==0.1.3
Requires-Dist: mss==9.0.1
Requires-Dist: numpy==1.26.1
Requires-Dist: openai==1.2.3
Requires-Dist: packaging==23.2
Requires-Dist: Pillow==10.1.0
Requires-Dist: prompt-toolkit==3.0.39
Requires-Dist: PyAutoGUI==0.9.54
Requires-Dist: pydantic==2.4.2
Requires-Dist: pydantic_core==2.10.1
Requires-Dist: PyGetWindow==0.0.9
Requires-Dist: PyMsgBox==1.0.9
Requires-Dist: pyparsing==3.1.1
Requires-Dist: pyperclip==1.8.2
Requires-Dist: PyRect==0.2.0
Requires-Dist: pyscreenshot==3.1
Requires-Dist: PyScreeze==0.1.29
Requires-Dist: python3-xlib==0.15
Requires-Dist: python-dateutil==2.8.2
Requires-Dist: python-dotenv==1.0.0
Requires-Dist: pytweening==1.0.7
Requires-Dist: requests==2.31.0
Requires-Dist: rubicon-objc==0.4.7
Requires-Dist: six==1.16.0
Requires-Dist: sniffio==1.3.0
Requires-Dist: tqdm==4.66.1
Requires-Dist: typing_extensions==4.8.0
Requires-Dist: urllib3==2.0.7
Requires-Dist: wcwidth==0.2.9
Requires-Dist: zipp==3.17.0
Requires-Dist: google-generativeai==0.3.0
Requires-Dist: aiohttp==3.9.1
Requires-Dist: ultralytics==8.0.227
Requires-Dist: easyocr==1.7.1
Requires-Dist: ollama==0.1.6
Requires-Dist: anthropic
Requires-Dist: Flask==2.2.5
Requires-Dist: Flask-Cors==3.0.10

# Realtime API Agents Demo

This is a simple demonstration of more advanced, agentic patterns built on top of the Realtime API. In particular, this demonstrates:
- Sequential agent handoffs according to a defined agent graph (taking inspiration from [OpenAI Swarm](https://github.com/openai/swarm))
- Background escalation to more intelligent models like o1-mini for high-stakes decisions
- Prompting models to follow a state machine, for example to accurately collect things like names and phone numbers with confirmation character by character to authenticate a user.

You should be able to use this repo to prototype your own multi-agent realtime voice app in less than 20 minutes!

![Screenshot of the Realtime API Agents Demo](/public/screenshot.png)

## Setup

- This is a Next.js typescript app
- Install dependencies with `npm i`
- Add your `OPENAI_API_KEY` to your env
- Start the server with `npm run dev`
- Open your browser to [http://localhost:3000](http://localhost:3000) to see the app. It should automatically connect to the `simpleExample` Agent Set.

## Configuring Agents
Configuration in `src/app/agentConfigs/simpleExample.ts`
```javascript
import { AgentConfig } from "@/app/types";
import { injectTransferTools } from "./utils";

// Define agents
const haiku: AgentConfig = {
  name: "haiku",
  publicDescription: "Agent that writes haikus.", // Context for the agent_transfer tool
  instructions:
    "Ask the user for a topic, then reply with a haiku about that topic.",
  tools: [],
};

const greeter: AgentConfig = {
  name: "greeter",
  publicDescription: "Agent that greets the user.",
  instructions:
    "Please greet the user and ask them if they'd like a Haiku. If yes, transfer them to the 'haiku' agent.",
  tools: [],
  downstreamAgents: [haiku],
};

// add the transfer tool to point to downstreamAgents
const agents = injectTransferTools([greeter, haiku]);

export default agents;
```

This fully specifies the agent set that was used in the interaction shown in the screenshot above.

### Next steps
- Check out the configs in `src/app/agentConfigs`. The example above is a minimal demo that illustrates the core concepts.
- [frontDeskAuthentication](src/app/agentConfigs/frontDeskAuthentication) Guides the user through a step-by-step authentication flow, confirming each value character-by-character, authenticates the user with a tool call, and then transfers to another agent. Note that the second agent is intentionally "bored" to show how to prompt for personality and tone.
- [customerServiceRetail](src/app/agentConfigs/customerServiceRetail) Also guides through an authentication flow, reads a long offer from a canned script verbatim, and then walks through a complex return flow which requires looking up orders and policies, gathering user context, and checking with `o1-mini` to ensure the return is eligible. To test this flow, say that you'd like to return your snowboard and go through the necessary prompts!

### Defining your own agents
- You can copy these to make your own multi-agent voice app! Once you make a new agent set config, add it to `src/app/agentConfigs/index.ts` and you should be able to select it in the UI in the "Scenario" dropdown menu.
- To see how to define tools and toolLogic, including a background LLM call, see [src/app/agentConfigs/customerServiceRetail/returns.ts](src/app/agentConfigs/customerServiceRetail/returns.ts)
- To see how to define a detailed personality and tone, and use a prompt state machine to collect user information step by step, see [src/app/agentConfigs/frontDeskAuthentication/authentication.ts](src/app/agentConfigs/frontDeskAuthentication/authentication.ts)
- To see how to wire up Agents into a single Agent Set, see [src/app/agentConfigs/frontDeskAuthentication/index.ts](src/app/agentConfigs/frontDeskAuthentication/index.ts)
- If you want help creating your own prompt using these conventions, we've included a metaprompt [here](src/app/agentConfigs/voiceAgentMetaprompt.txt), or you can use our [Voice Agent Metaprompter GPT](https://chatgpt.com/g/g-678865c9fb5c81918fa28699735dd08e-voice-agent-metaprompt-gpt)

## UI
- You can select agent scenarios in the Scenario dropdown, and automatically switch to a specific agent with the Agent dropdown.
- The conversation transcript is on the left, including tool calls, tool call responses, and agent changes. Click to expand non-message elements.
- The event log is on the right, showing both client and server events. Click to see the full payload.
- On the bottom, you can disconnect, toggle between automated voice-activity detection or PTT, turn off audio playback, and toggle logs.

## Core Contributors
- Noah MacCallum - [noahmacca](https://x.com/noahmacca)
- Ilan Bigio - [ibigio](https://github.com/ibigio)
